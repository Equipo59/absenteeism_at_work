# MLOps - Absenteeism at Work


## Project

Model to predict how many hours an employee will be absent.


## Value Proposition

Anticipate absenteeism trends to improve operational planning, reduce costs, and promote employee well-being strategies.


## Roles
**Data Engineer**: Miguel Marines  
**Data Scientist**: Jorge AdriÃ¡n Acevedo Fonseca  
**Machine Learning Engineer**: Eduardo Javier Porras Herrera  
**Software Engineer**: Carlos Pano HernÃ¡ndez  
**Site Reliability Engineer (DevOps)**: CÃ©sar Manuel Tirado Peraza






## Project Organization

This project follows the [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/) structure for organized and reproducible machine learning projects.

```
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile                          # Standard commands for project operations
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml                    # Project metadata and build configuration
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ setup.cfg                         # Additional setup configuration
â”œâ”€â”€ .dvcignore                        # Files to ignore in DVC tracking
â”œâ”€â”€ dvc.yaml                          # DVC pipeline definition
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external                      # External data sources
â”‚   â”œâ”€â”€ interim                       # Intermediate data files
â”‚   â”œâ”€â”€ processed                     # Final, processed datasets
â”‚   â”‚   â””â”€â”€ work_absenteeism_processed.csv
â”‚   â””â”€â”€ raw                           # Original, immutable data
â”‚       â””â”€â”€ work_absenteeism_raw.csv
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ Phase1.pdf
â”‚   â””â”€â”€ Phase2.pdf
â”œâ”€â”€ models                            # Trained and serialized models
â”œâ”€â”€ notebooks                         # Jupyter notebooks for exploration
â”‚   â””â”€â”€ Phase1
â”‚       â”œâ”€â”€ data_preparation.ipynb
â”‚       â”œâ”€â”€ eda_fe.ipynb
â”‚       â””â”€â”€ model_train.ipynb
â”œâ”€â”€ references                        # Data dictionaries, papers, manuals
â”œâ”€â”€ reports
â”‚   â”œâ”€â”€ figures                       # Generated graphics and figures
â”‚   â””â”€â”€ metrics                       # Model evaluation metrics
â”œâ”€â”€ .dvc/                             # DVC configuration (hidden)
â”‚   â”œâ”€â”€ config
â”‚   â”œâ”€â”€ plots/
â”‚   â””â”€â”€ tmp/
â””â”€â”€ absenteeism_at_work               # Source code package
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.py                    # Configuration and constants
    â”œâ”€â”€ dataset.py                   # Data loading and cleaning
    â”œâ”€â”€ features.py                  # Feature engineering pipeline
    â”œâ”€â”€ modeling
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ predict.py              # Model prediction interface
    â”‚   â””â”€â”€ train.py                # Model training pipeline
    â”œâ”€â”€ plots.py                     # Visualization functions
    â”œâ”€â”€ preprocess_data.py           # Data preprocessing entry point
    â””â”€â”€ visualize_data.py            # Visualization entry point
```

## Quick Start

### Installation

```bash
# Install the package in development mode
make install

# Or with all optional dependencies
make install-dev
```

### Using Make Commands

```bash
# See all available commands
make help

# Preprocess raw data
make preprocess

# Train the model
make train

# Generate visualizations
make visualize

# Run full pipeline
make all

# Run tests
make test

# Format code
make format
```

### Using DVC

```bash
# Pull data versions
make data-pull

# Check data status
make data-version

# Run DVC pipeline
dvc repro
```

## ðŸš€ Deployment

### Branch Strategy

- **`master`/`main`**: Desarrollo (sin deploy automÃ¡tico)
- **`web`**: ProducciÃ³n (deploy automÃ¡tico a ECS Fargate)

### Deploy to Production

El workflow de GitHub Actions se ejecutarÃ¡ automÃ¡ticamente al hacer push a la rama `web`:

```bash
# When ready to deploy
git checkout web
git merge master
git push origin web
```

### What Gets Deployed

**1. Absenteeism API** (deploy.yml)
- âœ… **CloudFormation** para infraestructura
- âœ… **ECR** para imÃ¡genes Docker (`absenteeism-api`)
- âœ… **ECS Cluster**: `production-absenteeism-cluster`
- âœ… **Application Load Balancer** para alta disponibilidad
- âœ… **Auto-scaling** y health checks
- âœ… **Logs centralizados** en CloudWatch

**2. MLflow Tracking Server** (deploy-mlflow.yml)
- âœ… **CloudFormation** para infraestructura
- âœ… **ECR** para imÃ¡genes Docker (`mlflow-tracking`)
- âœ… **ECS Cluster**: `production-mlflow-cluster`
- âœ… **Application Load Balancer** para acceder a la UI
- âœ… **S3** para almacenar artifacts (opcional)
- âœ… **Health checks** para el servidor de tracking

### Troubleshooting

**Ver logs de ECS (API):**
```bash
aws logs tail /ecs/production-absenteeism-api --follow --region us-east-1
```

**Ver logs de ECS (MLflow):**
```bash
aws logs tail /ecs/production-mlflow-tracking --follow --region us-east-1
```

**Verificar estado del servicio (API):**
```bash
aws ecs describe-services \
  --cluster production-absenteeism-cluster \
  --services production-absenteeism-api \
  --region us-east-1
```

**Verificar estado del servicio (MLflow):**
```bash
aws ecs describe-services \
  --cluster production-mlflow-cluster \
  --services production-mlflow-tracking \
  --region us-east-1
```

**Ver outputs de CloudFormation (API):**
```bash
aws cloudformation describe-stacks \
  --stack-name absenteeism-infrastructure \
  --query 'Stacks[0].Outputs' \
  --output table \
  --region us-east-1
```

**Ver outputs de CloudFormation (MLflow):**
```bash
aws cloudformation describe-stacks \
  --stack-name mlflow-infrastructure \
  --query 'Stacks[0].Outputs' \
  --output table \
  --region us-east-1
```

## Project Structure Based on Cookiecutter Data Science

This project follows the standardized structure recommended by [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/), which provides:

- **Standardized organization**: Consistent project structure across different ML projects
- **Separation of concerns**: Clear separation between data, code, models, and documentation
- **Reproducibility**: Structured approach to version control and experiment tracking
- **Scalability**: Easy to extend and maintain as the project grows

Key principles implemented:
- Raw data is immutable and versioned with DVC
- Processed data is derived from raw data through documented pipelines
- Code is organized into logical modules
- Models are versioned and tracked with MLflow
- Experiments are reproducible through DVC pipelines

--------

